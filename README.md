# BasicKnowledge-Computer
计算机科学、人工智能领域的基础知识。

目前分为计算机基础、机器学习、深度学习、智力题四部分，持续学习更新中。

## 计算机基础

未整理：
- 数据结构
- 算法编程

## 机器学习

已整理：
- 最大似然估计
- 隐变量模型
- EM算法

未整理：
- SVM
- 降维算法（SVD和PCA）
- K-Means（手撕代码实现）
- 决策树（各种生成和剪枝方法）
- 集成学习（随机森林、XGBoost、AdaBoost、GBDT）
- 岭回归

## 深度学习

已整理：
- 信息论（信息熵、条件熵、联合熵、相对熵、互信息的概念，交叉熵和KL散度区别）
- 激活函数（优缺点，sigmoid、tanh、relu、gelu）

未整理：
- LR（为啥用sigmoid函数，交叉熵推导，MAE和MLP，反向传播，归一化，正则化）
- 过拟合（正则化、增加训练数据、数据增强、标签平滑、BatchNorm、Early-Stop、交叉验证、Dropout、Pre-trained、引入先验知识）
- 方差偏差分解（解释什么是方差什么是偏差，公式推导）
- 正则化（L1和L2的会有啥现象、解释原因、分别代表什么先验，bias要不要正则）
- 初始化（不同网络初始化有啥区别，神经网络隐层可以全部初始化为0吗）
- 损失函数（用过哪些损失函数，为啥分类不用MSE）
- 梯度消失（残差、门控、sigmoid换relu、归一化）
- 梯度爆炸（截断）
- 归一化（为什么要做归一化，各种归一化的区别和优缺点，NLP为啥不用BatchNorm）
- 优化器（原理和演进过程，SGD、AdaGrad、RMSprop、AdaDelta、Adam、AdamW）
- 显存爆炸（重计算、梯度累加、混合精度训练、Adam换成SGD、多用inplace）
- 学习率（衰减、warmup、自适应、平时自己使用的时候对lr有什么调整心得吗）
- 样本不均衡（降/过采样和带权重的loss）
- 数据预处理（离散特征和连续特征）
- 评价指标（Acc、Precision、Recall、F1、ROC、AUC、代码实现AUC）
- 神经网络（优缺点、演进和公式推导，lstm、cnn、transformer）
- OOV咋办
- 分布式学习

## 智力题

未整理：
- 用rand7构造rand10
- 山羊汽车问题
- 木棍截成三段，形成三角形的概率
- 抛一个6面的骰子，连续抛直到6为止，问期望的抛的次数是多少
- 给定概率不均匀的0和1随机生成器，怎样等概率随机生成0和1
- 三角形里面随机选3个点，构成锐角三角形的概率
- 两个人轮流抛硬币，规定第一个抛出正面的人可以吃苹果，求先抛的人吃苹果的概率
- 一副扑克牌，分成三堆，大小王出现在同一份的概率
- 在半径为1的圆内随机等概率采样一个点
